import streamlit as st
import cv2
import numpy as np
from PIL import Image
from transformers import pipeline
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration
import io
import time

# Page config
st.set_page_config(page_title="Advanced Sentiment Analyzer by AMAN", page_icon="üé≠", layout="wide")

# Sidebar
st.sidebar.title("Settings ‚öôÔ∏è")
dark = st.sidebar.checkbox("Enable Dark Mode")
if dark:
    st.markdown("""
        <style>
        .stApp { background:#121212; color:#EEE; }
        .stTextArea>div>div>textarea, .stButton>button { background:#333; color:#EEE; }
        </style>
    """, unsafe_allow_html=True)

# Load models
@st.cache_resource
def load_nlp():
    return pipeline("text-classification", model="j-hartmann/emotion-english-distilroberta-base", return_all_scores=True)

nlp_model = load_nlp()

# Detailed emotion descriptions
emotion_descriptions = {
    "joy": {
        "title": "‡§ñ‡•Å‡§∂‡•Ä üòä",
        "description": "‡§Ü‡§™ ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂ ‡§î‡§∞ ‡§™‡•ç‡§∞‡§∏‡§®‡•ç‡§® ‡§π‡•à‡§Ç‡•§ ‡§Ø‡§π ‡§≠‡§æ‡§µ‡§®‡§æ ‡§Ü‡§™‡§ï‡•ã ‡§ä‡§∞‡•ç‡§ú‡§æ‡§µ‡§æ‡§® ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞‡§æ‡§§‡•Ä ‡§π‡•à ‡§î‡§∞ ‡§¶‡•Ç‡§∏‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ú‡•Å‡§°‡§º‡§®‡•á ‡§ï‡•Ä ‡§á‡§ö‡•ç‡§õ‡§æ ‡§¨‡§¢‡§º‡§æ‡§§‡•Ä ‡§π‡•à‡•§",
        "advice": "‡§á‡§∏ ‡§ñ‡•Å‡§∂‡•Ä ‡§ï‡•ã ‡§Ö‡§™‡§®‡•á ‡§¶‡•ã‡§∏‡•ç‡§§‡•ã‡§Ç ‡§î‡§∞ ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§∂‡•á‡§Ø‡§∞ ‡§ï‡§∞‡•á‡§Ç!"
    },
    "sadness": {
        "title": "‡§â‡§¶‡§æ‡§∏‡•Ä üò¢",
        "description": "‡§Ü‡§™ ‡§•‡•ã‡§°‡§º‡§æ ‡§â‡§¶‡§æ‡§∏ ‡§Ø‡§æ ‡§Æ‡§® ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§∞‡•Ä‡§™‡§® ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ ‡§Ø‡§π ‡§è‡§ï ‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï ‡§≠‡§æ‡§µ‡§®‡§æ ‡§π‡•à ‡§ú‡•ã ‡§ï‡§≠‡•Ä-‡§ï‡§≠‡•Ä ‡§∏‡§≠‡•Ä ‡§ï‡•ã ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§",
        "advice": "‡§Ö‡§™‡§®‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡§∞‡•Ä‡§¨‡•Ä ‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§Ø‡§æ ‡§ï‡•ã‡§à ‡§Ö‡§ö‡•ç‡§õ‡•Ä activity ‡§ï‡§∞‡•á‡§Ç‡•§"
    },
    "anger": {
        "title": "‡§ó‡•Å‡§∏‡•ç‡§∏‡§æ üò†", 
        "description": "‡§Ü‡§™ ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§ó‡•Å‡§∏‡•ç‡§∏‡•á ‡§Ø‡§æ ‡§ö‡§ø‡§¢‡§º‡§æ‡§π‡§ü ‡§ï‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§Æ‡•á‡§Ç ‡§π‡•à‡§Ç‡•§ ‡§Ø‡§π ‡§≠‡§æ‡§µ‡§®‡§æ ‡§§‡§¨ ‡§Ü‡§§‡•Ä ‡§π‡•à ‡§ú‡§¨ ‡§ï‡•Å‡§õ ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã‡§§‡§æ‡•§",
        "advice": "‡§ó‡§π‡§∞‡•Ä ‡§∏‡§æ‡§Ç‡§∏ ‡§≤‡•á‡§Ç ‡§î‡§∞ ‡§•‡•ã‡§°‡§º‡§æ ‡§Ü‡§∞‡§æ‡§Æ ‡§ï‡§∞‡•á‡§Ç‡•§ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§ï‡§æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§∂‡§æ‡§Ç‡§§‡§ø ‡§∏‡•á ‡§∏‡•ã‡§ö‡•á‡§Ç‡•§"
    },
    "fear": {
        "title": "‡§°‡§∞ üò®",
        "description": "‡§Ü‡§™ ‡§ï‡§ø‡§∏‡•Ä ‡§ö‡•Ä‡§ú‡§º ‡§ï‡•ã ‡§≤‡•á‡§ï‡§∞ ‡§ö‡§ø‡§Ç‡§§‡§ø‡§§ ‡§Ø‡§æ ‡§°‡§∞‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç‡•§ ‡§Ø‡§π ‡§≠‡§æ‡§µ‡§®‡§æ ‡§π‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§∞‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§",
        "advice": "‡§Ö‡§™‡§®‡•á ‡§°‡§∞ ‡§ï‡§æ ‡§ï‡§æ‡§∞‡§£ ‡§™‡§π‡§ö‡§æ‡§®‡•á‡§Ç ‡§î‡§∞ ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡§∞‡•ã‡§∏‡•á‡§Æ‡§Ç‡§¶ ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø ‡§∏‡•á ‡§∏‡§≤‡§æ‡§π ‡§≤‡•á‡§Ç‡•§"
    },
    "surprise": {
        "title": "‡§Ü‡§∂‡•ç‡§ö‡§∞‡•ç‡§Ø üò≤",
        "description": "‡§Ü‡§™ ‡§ï‡§ø‡§∏‡•Ä ‡§Ö‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡§æ‡§∂‡§ø‡§§ ‡§Ø‡§æ ‡§®‡§à ‡§¨‡§æ‡§§ ‡§∏‡•á ‡§π‡•à‡§∞‡§æ‡§® ‡§π‡•à‡§Ç‡•§ ‡§Ø‡§π ‡§≠‡§æ‡§µ‡§®‡§æ ‡§®‡§à ‡§ö‡•Ä‡§ú‡§º‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•Ä‡§ñ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à‡•§",
        "advice": "‡§á‡§∏ ‡§®‡§è ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§ï‡§æ ‡§Ü‡§®‡§Ç‡§¶ ‡§≤‡•á‡§Ç ‡§î‡§∞ ‡§ú‡•ã ‡§∏‡•Ä‡§ñ‡§æ ‡§π‡•à ‡§â‡§∏‡•á ‡§Ø‡§æ‡§¶ ‡§∞‡§ñ‡•á‡§Ç‡•§"
    },
    "disgust": {
        "title": "‡§ò‡•É‡§£‡§æ ü§¢",
        "description": "‡§Ü‡§™ ‡§ï‡§ø‡§∏‡•Ä ‡§ö‡•Ä‡§ú‡§º ‡§∏‡•á ‡§®‡§´‡§∞‡§§ ‡§Ø‡§æ ‡§Ö‡§∞‡•Å‡§ö‡§ø ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ ‡§Ø‡§π ‡§≠‡§æ‡§µ‡§®‡§æ ‡§π‡§Æ‡•á‡§Ç ‡§®‡•Å‡§ï‡§∏‡§æ‡§®‡§¶‡§æ‡§Ø‡§ï ‡§ö‡•Ä‡§ú‡§º‡•ã‡§Ç ‡§∏‡•á ‡§¨‡§ö‡§æ‡§§‡•Ä ‡§π‡•à‡•§",
        "advice": "‡§â‡§∏ ‡§ö‡•Ä‡§ú‡§º ‡§∏‡•á ‡§¶‡•Ç‡§∞‡•Ä ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡•á‡§Ç ‡§ú‡•ã ‡§Ü‡§™‡§ï‡•ã ‡§™‡§∞‡•á‡§∂‡§æ‡§® ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•à‡•§"
    },
    "neutral": {
        "title": "‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø üòê",
        "description": "‡§Ü‡§™ ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§∂‡§æ‡§Ç‡§§ ‡§î‡§∞ ‡§∏‡§Ç‡§§‡•Å‡§≤‡§ø‡§§ ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§Æ‡•á‡§Ç ‡§π‡•à‡§Ç‡•§ ‡§ï‡•ã‡§à ‡§ñ‡§æ‡§∏ ‡§≠‡§æ‡§µ‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§â‡§§‡§æ‡§∞-‡§ö‡§¢‡§º‡§æ‡§µ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§",
        "advice": "‡§Ø‡§π ‡§è‡§ï ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§π‡•à‡•§ ‡§á‡§∏‡§ï‡§æ ‡§´‡§æ‡§Ø‡§¶‡§æ ‡§â‡§†‡§æ‡§ï‡§∞ ‡§ï‡•Å‡§õ productive ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡•á‡§Ç‡•§"
    }
}

def analyze_text_detailed(txt):
    if nlp_model:
        scores = nlp_model(txt)[0]
        top = max(scores, key=lambda x: x["score"])
        emotion_key = top['label'].lower()
        confidence = top['score'] * 100
        
        if emotion_key in emotion_descriptions:
            emotion_info = emotion_descriptions[emotion_key]
            return {
                "emotion": emotion_info["title"],
                "confidence": confidence,
                "description": emotion_info["description"],
                "advice": emotion_info["advice"]
            }
    
    return {
        "emotion": "‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø üòê",
        "confidence": 50,
        "description": "‡§Ü‡§™‡§ï‡•Ä ‡§≠‡§æ‡§µ‡§®‡§æ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§",
        "advice": "‡§Ö‡§ß‡§ø‡§ï ‡§µ‡§ø‡§∏‡•ç‡§§‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§è‡§Ç ‡§ï‡§ø ‡§Ü‡§™ ‡§ï‡•à‡§∏‡§æ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§"
    }

# Webcam photo capture
def capture_webcam_photo():
    st.markdown("### üì∑ Webcam ‡§∏‡•á Photo ‡§≤‡•á‡§Ç:")
    
    picture = st.camera_input("‡§Ö‡§™‡§®‡•Ä ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞ ‡§ñ‡•Ä‡§Ç‡§ö‡•á‡§Ç")
    
    if picture is not None:
        # Analyze the photo
        img_analysis = analyze_photo_emotion(picture.read())
        return img_analysis
    return None

def analyze_photo_emotion(img_bytes):
    img = Image.open(io.BytesIO(img_bytes))
    img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
    
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=6, minSize=(50, 50))
    
    if len(faces) > 0:
        for (x, y, w, h) in faces:
            cv2.rectangle(img_cv, (x, y), (x+w, y+h), (0, 255, 0), 2)
            
            # Simple emotion detection based on facial features
            face_region = gray[y:y+h, x:x+w]
            brightness = np.mean(face_region)
            contrast = np.std(face_region)
            
            # Emotion prediction logic
            if brightness > 120 and contrast > 40:
                emotion_key = "joy"
            elif brightness < 90:
                emotion_key = "sadness"
            elif contrast > 50:
                emotion_key = "surprise"
            else:
                emotion_key = "neutral"
            
            if emotion_key in emotion_descriptions:
                emotion_info = emotion_descriptions[emotion_key]
                result_img = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))
                
                return {
                    "image": result_img,
                    "emotion": emotion_info["title"],
                    "description": emotion_info["description"],
                    "advice": emotion_info["advice"],
                    "confidence": 85
                }
    
    return {
        "image": img,
        "emotion": "No face detected",
        "description": "‡§ï‡•ã‡§à ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§ö‡•á‡§π‡§∞‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ‡•§",
        "advice": "‡§¨‡•á‡§π‡§§‡§∞ lighting ‡§Æ‡•á‡§Ç ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§",
        "confidence": 0
    }

# UI Layout
st.markdown("<h1 style='text-align:center;'>üé≠ Advanced Sentiment Analyzer by AMAN</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center;'>Text ‡§î‡§∞ Photo ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§∏‡•á detailed emotion analysis ‡§ï‡§∞‡•á‡§Ç</p>", unsafe_allow_html=True)

# Create tabs
tab1, tab2, tab3 = st.tabs(["üìù Text Analysis", "üì∑ Photo Upload", "üé• Webcam Capture"])

with tab1:
    st.subheader("‡§Ö‡§™‡§®‡•á ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§Ø‡§æ ‡§≠‡§æ‡§µ‡§®‡§æ‡§è‡§Ç ‡§≤‡§ø‡§ñ‡•á‡§Ç:")
    user_text = st.text_area("", height=150, placeholder="‡§ú‡•à‡§∏‡•á: '‡§Ü‡§ú ‡§Æ‡•à‡§Ç ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂ ‡§π‡•Ç‡§Ç ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Æ‡•á‡§∞‡§æ interview ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ó‡§Ø‡§æ'")
    
    if st.button("üîç Analyze ‡§ï‡§∞‡•á‡§Ç"):
        if user_text:
            result = analyze_text_detailed(user_text)
            st.session_state.text_analysis = result

    if "text_analysis" in st.session_state:
        result = st.session_state.text_analysis
        st.markdown(f"### {result['emotion']} ({result['confidence']:.1f}%)")
        st.info(result['description'])
        st.success(f"üí° ‡§∏‡•Å‡§ù‡§æ‡§µ: {result['advice']}")

with tab2:
    st.subheader("Photo Upload ‡§ï‡§∞‡•á‡§Ç:")
    uploaded_file = st.file_uploader("‡§Ö‡§™‡§®‡•Ä ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞ ‡§ö‡•Å‡§®‡•á‡§Ç", type=["jpg", "jpeg", "png"])
    
    if uploaded_file:
        photo_result = analyze_photo_emotion(uploaded_file.read())
        st.image(photo_result["image"], caption=photo_result["emotion"])
        st.markdown(f"### {photo_result['emotion']} ({photo_result['confidence']}%)")
        st.info(photo_result['description'])
        if photo_result['advice']:
            st.success(f"üí° ‡§∏‡•Å‡§ù‡§æ‡§µ: {photo_result['advice']}")

with tab3:
    st.subheader("Live Webcam ‡§∏‡•á Photo:")
    webcam_result = capture_webcam_photo()
    
    if webcam_result:
        st.image(webcam_result["image"], caption=webcam_result["emotion"])
        st.markdown(f"### {webcam_result['emotion']} ({webcam_result['confidence']}%)")
        st.info(webcam_result['description'])
        if webcam_result['advice']:
            st.success(f"üí° ‡§∏‡•Å‡§ù‡§æ‡§µ: {webcam_result['advice']}")

# Footer
st.markdown("---")
st.markdown("<div style='text-align:center;color:gray;'>Made with ‚ù§Ô∏è by AMAN - Advanced Emotion Intelligence</div>", unsafe_allow_html=True)
